# ğŸ“ NanoGrid v2 - íŒŒíŠ¸ë³„ ìƒì„¸ ê°œë°œ ìš”êµ¬ì‚¬í•­ (R&R)

> **ì•„í‚¤í…ì²˜ ë³€ê²½**: Lambda ê¸°ë°˜ â†’ EC2 Controller ê¸°ë°˜ 3-Tier êµ¬ì¡°  
> **ì‹ ê·œ ê¸°ëŠ¥**: AI Node (Ollama LLM), Output Binding (S3 ê²°ê³¼ë¬¼ ìë™ ì—…ë¡œë“œ)  
> **ìµœì¢… ìˆ˜ì •ì¼**: 2024-12-04

---

## ğŸ—ï¸ 1. Infrastructure Team (Terraform)

### ğŸ“Œ ëª©í‘œ
Lambdaë¥¼ ì² ê±°í•˜ê³ , ALB â†’ Controller â†’ Worker/Redis 3-Tier êµ¬ì¡°ì™€ AI ì¸í”„ë¼ë¥¼ êµ¬ì¶•í•©ë‹ˆë‹¤.

### âœ… ì™„ë£Œëœ ì‘ì—… (Terraform Apply ì™„ë£Œ)

#### 1.1 ë„¤íŠ¸ì›Œí¬ êµ¬ì„±
```
VPC: nanogrid-vpc (10.0.0.0/16)
â”œâ”€â”€ Public Subnet 1 (10.0.1.0/24, AZ-a) â† Controller EC2, NAT GW
â”œâ”€â”€ Public Subnet 2 (10.0.2.0/24, AZ-c) â† ALB Multi-AZ ìš”êµ¬ì‚¬í•­
â”œâ”€â”€ Private-App Subnet (10.0.10.0/24)  â† í˜„ì¬ ë¯¸ì‚¬ìš© (í–¥í›„ í™•ì¥ìš©)
â””â”€â”€ Private-Data Subnet (10.0.20.0/24) â† Worker ASG, AI Node, Redis
```

#### 1.2 ì»´í“¨íŒ… ë¦¬ì†ŒìŠ¤
| ë¦¬ì†ŒìŠ¤ | íƒ€ì… | ìœ„ì¹˜ | IP | ìƒíƒœ |
|--------|------|------|-----|------|
| ALB | Application LB | Public Subnet 1,2 | DNS ì œê³µ | âœ… |
| Controller EC2 | t3.small | Public Subnet 1 | 10.0.1.84 | âœ… |
| Worker ASG | t3.small | Private-Data | ë™ì  í• ë‹¹ | âœ… |
| AI Node EC2 | t3.large | Private-Data | 10.0.20.100 | âœ… |
| Redis | cache.t3.micro | Private-Data | ë™ì  í• ë‹¹ | âœ… |

#### 1.3 ë³´ì•ˆ ê·¸ë£¹ ë§¤íŠ¸ë¦­ìŠ¤
| SG | Inbound | Source | ìš©ë„ |
|----|---------|--------|------|
| alb-sg | 80, 443 | 0.0.0.0/0 | ì™¸ë¶€ íŠ¸ë˜í”½ |
| controller-sg | 80 | alb-sg | ALB â†’ Controller |
| controller-sg | 22, 8080 | 0.0.0.0/0 | SSH, Express ì§ì ‘ ì ‘ê·¼ |
| worker-sg | - | - | Outboundë§Œ í—ˆìš© |
| ai-sg | 11434 | worker-sg | Worker â†’ AI Node |
| redis-sg | 6379 | controller-sg, worker-sg | Redis ì ‘ê·¼ |

#### 1.4 IAM ê¶Œí•œ
**Controller Role:**
- S3: PutObject, GetObject, DeleteObject (`nanogrid-code-bucket`)
- DynamoDB: PutItem, GetItem, UpdateItem, Query, DeleteItem
- SQS: SendMessage, GetQueueAttributes

**Worker Role:**
- S3: GetObject (`nanogrid-code-bucket`), PutObject (`nanogrid-user-data`)
- SQS: ReceiveMessage, DeleteMessage, GetQueueAttributes
- DynamoDB: GetItem
- CloudWatch: Agent ê¶Œí•œ

### ğŸ”² ë‚¨ì€ ì‘ì—…
- [ ] HTTPS ì¸ì¦ì„œ (ACM) ë° ALB HTTPS Listener ì¶”ê°€
- [ ] Route53 ë„ë©”ì¸ ì—°ê²° (ì„ íƒ)
- [ ] CloudWatch ëŒ€ì‹œë³´ë“œ êµ¬ì„±

---

## âš™ï¸ 2. Backend Team (Controller Node - Express.js)

### ğŸ“Œ ëª©í‘œ
ê¸°ì¡´ Lambda 2ê°œ(Upload, Run)ì˜ ì—­í• ì„ Express.js ì„œë²„ í•˜ë‚˜ë¡œ í†µí•©í•©ë‹ˆë‹¤.

### ğŸ”² ê°œë°œ ì‘ì—…

#### 2.1 EC2 ì ‘ì† ë° í™˜ê²½ ì„¤ì •
```bash
# SSH ì ‘ì† (Public IP ë˜ëŠ” Session Manager)
ssh -i key.pem ubuntu@<controller-public-ip>

# ë˜ëŠ” AWS Systems Manager Session Manager ì‚¬ìš©
aws ssm start-session --target <instance-id>
```

**í™˜ê²½ë³€ìˆ˜ (Terraformì—ì„œ ìë™ ì£¼ì…ë¨ - /etc/environment):**
```bash
S3_BUCKET=nanogrid-code-bucket
DYNAMODB_TABLE=NanoGridFunctions
SQS_QUEUE_URL=https://sqs.ap-northeast-2.amazonaws.com/xxx/nanogrid-task-queue
REDIS_HOST=nanogrid-redis.xxx.cache.amazonaws.com
REDIS_PORT=6379
```

#### 2.2 Express ì„œë²„ êµ¬ì¶• (server.js)

```javascript
// í•„ìš” íŒ¨í‚¤ì§€
// npm install express aws-sdk ioredis uuid multer

const express = require('express');
const AWS = require('aws-sdk');
const Redis = require('ioredis');
const { v4: uuidv4 } = require('uuid');
const multer = require('multer');

const app = express();
const upload = multer({ storage: multer.memoryStorage() });

// AWS í´ë¼ì´ì–¸íŠ¸
const s3 = new AWS.S3();
const dynamodb = new AWS.DynamoDB.DocumentClient();
const sqs = new AWS.SQS();

// Redis í´ë¼ì´ì–¸íŠ¸
const redis = new Redis({
  host: process.env.REDIS_HOST,
  port: process.env.REDIS_PORT
});

// Health Check (ALBìš© - í•„ìˆ˜!)
app.get('/health', (req, res) => {
  res.status(200).json({ status: 'healthy' });
});

// POST /upload - íŒŒì¼ ì—…ë¡œë“œ
app.post('/upload', upload.single('file'), async (req, res) => {
  // êµ¬í˜„ í•„ìš”
});

// POST /run - í•¨ìˆ˜ ì‹¤í–‰
app.post('/run', async (req, res) => {
  // êµ¬í˜„ í•„ìš”
});

app.listen(80, () => console.log('Controller running on port 80'));
```

#### 2.3 API ìƒì„¸ ìŠ¤í™

##### `POST /upload` - í•¨ìˆ˜ ë“±ë¡
```
Request:
  - Content-Type: multipart/form-data
  - Body:
    - file: ì†ŒìŠ¤ì½”ë“œ íŒŒì¼ (.py, .zip ë“±)
    - function_name: í•¨ìˆ˜ ì´ë¦„ (string)
    - runtime: ëŸ°íƒ€ì„ (python3.9, nodejs18.x ë“±)
    - handler: í•¸ë“¤ëŸ¬ (ì˜ˆ: main.handler)
    - timeout: íƒ€ì„ì•„ì›ƒ ì´ˆ (ê¸°ë³¸ 300)

Response (201 Created):
{
  "function_id": "uuid-xxxx",
  "function_name": "my-function",
  "s3_key": "functions/uuid-xxxx/code.zip",
  "created_at": "2024-12-04T10:00:00Z"
}

ë¡œì§:
1. UUID ìƒì„±
2. S3ì— íŒŒì¼ ì—…ë¡œë“œ (Key: functions/{function_id}/code.zip)
3. DynamoDBì— ë©”íƒ€ë°ì´í„° ì €ì¥
   - functionId (PK)
   - functionName
   - s3Key
   - runtime
   - handler
   - timeout
   - createdAt
```

##### `POST /run` - í•¨ìˆ˜ ì‹¤í–‰ (ë™ê¸°)
```
Request:
  - Content-Type: application/json
  - Headers:
    - X-Async: true (ì„ íƒ, ë¹„ë™ê¸° ëª¨ë“œ)
  - Body:
{
  "function_id": "uuid-xxxx",
  "payload": { "key": "value" }
}

Response (200 OK) - ë™ê¸° ëª¨ë“œ:
{
  "job_id": "job-uuid-xxxx",
  "status": "completed",
  "result": { ... },
  "output_files": ["https://s3.../output/file1.png"],
  "execution_time_ms": 1234
}

Response (202 Accepted) - ë¹„ë™ê¸° ëª¨ë“œ:
{
  "job_id": "job-uuid-xxxx",
  "status": "pending",
  "message": "Job submitted. Poll GET /status/{job_id} for results."
}

ë¡œì§:
1. job_id (UUID) ìƒì„±
2. DynamoDBì—ì„œ function ë©”íƒ€ë°ì´í„° ì¡°íšŒ
3. SQSì— ë©”ì‹œì§€ ë°œí–‰:
   {
     "job_id": "job-uuid",
     "function_id": "func-uuid",
     "s3_key": "functions/xxx/code.zip",
     "runtime": "python3.9",
     "handler": "main.handler",
     "payload": { ... },
     "timeout": 300
   }
4. Redis Subscribeë¡œ ê²°ê³¼ ëŒ€ê¸° (ì±„ë„: result:{job_id})
   - íƒ€ì„ì•„ì›ƒ: 5ë¶„ (req.setTimeout(300000))
5. ê²°ê³¼ ìˆ˜ì‹  ì‹œ ì‘ë‹µ ë°˜í™˜
```

##### `GET /status/:job_id` - ì‘ì—… ìƒíƒœ ì¡°íšŒ (ë¹„ë™ê¸°ìš©)
```
Response:
{
  "job_id": "job-uuid-xxxx",
  "status": "completed" | "running" | "failed",
  "result": { ... },
  "output_files": [...]
}
```

#### 2.4 ì£¼ì˜ì‚¬í•­
- **ì†Œì¼“ íƒ€ì„ì•„ì›ƒ**: `req.setTimeout(300000)` í•„ìˆ˜ (ê¸°ë³¸ 2ë¶„ â†’ 5ë¶„)
- **ALB Idle Timeout**: Terraformì—ì„œ 300ì´ˆë¡œ ì„¤ì • í•„ìš”
- **Health Check**: `/health` ì—”ë“œí¬ì¸íŠ¸ í•„ìˆ˜ (ALBê°€ ì²´í¬í•¨)
- **PM2 ì‚¬ìš©**: `pm2 start server.js --name controller` (í”„ë¡œì„¸ìŠ¤ ê´€ë¦¬)

#### 2.5 ë°°í¬ ë°©ë²•
```bash
# Controller EC2ì—ì„œ
cd /home/ubuntu
git clone <your-repo> nanogrid-controller
cd nanogrid-controller
npm install
pm2 start server.js --name controller
pm2 save
pm2 startup  # ì¬ë¶€íŒ… ì‹œ ìë™ ì‹œì‘
```

---

## ğŸƒ 3. Data Plane Team (Worker Agent - Python)

### ğŸ“Œ ëª©í‘œ
SQSì—ì„œ ì‘ì—…ì„ ìˆ˜ì‹ í•˜ê³ , Docker ì»¨í…Œì´ë„ˆì—ì„œ ì‚¬ìš©ì ì½”ë“œë¥¼ ì‹¤í–‰í•œ ë’¤, ê²°ê³¼ë¥¼ Redisë¡œ ë°œí–‰í•©ë‹ˆë‹¤.  
**ê°€ì¥ í•µì‹¬ì ì¸ íŒŒíŠ¸ì…ë‹ˆë‹¤.**

### ğŸ”² ê°œë°œ ì‘ì—…

#### 3.1 Worker Agent êµ¬ì¡°
```
/home/ubuntu/nanogrid-worker/
â”œâ”€â”€ agent.py          # ë©”ì¸ ì—ì´ì „íŠ¸ (SQS Polling)
â”œâ”€â”€ executor.py       # Docker ì‹¤í–‰ ë¡œì§
â”œâ”€â”€ uploader.py       # S3 Output Binding
â”œâ”€â”€ requirements.txt  # boto3, redis, docker, requests
â””â”€â”€ Dockerfile        # (ì„ íƒ) Agent ìì²´ ì»¨í…Œì´ë„ˆí™”
```

#### 3.2 í™˜ê²½ë³€ìˆ˜ (Terraformì—ì„œ ìë™ ì£¼ì…ë¨)
```bash
S3_CODE_BUCKET=nanogrid-code-bucket
S3_USER_DATA_BUCKET=nanogrid-user-data-xxxxxxxxxxxx
SQS_QUEUE_URL=https://sqs.ap-northeast-2.amazonaws.com/xxx/nanogrid-task-queue
REDIS_HOST=nanogrid-redis.xxx.cache.amazonaws.com
REDIS_PORT=6379
AI_ENDPOINT=http://10.0.20.100:11434
```

#### 3.3 agent.py - ë©”ì¸ ë£¨í”„
```python
import boto3
import redis
import json
import os
from executor import run_container
from uploader import upload_outputs

sqs = boto3.client('sqs')
redis_client = redis.Redis(
    host=os.environ['REDIS_HOST'],
    port=int(os.environ['REDIS_PORT'])
)

QUEUE_URL = os.environ['SQS_QUEUE_URL']

def poll_and_execute():
    while True:
        # 1. SQSì—ì„œ ë©”ì‹œì§€ ìˆ˜ì‹  (Long Polling)
        response = sqs.receive_message(
            QueueUrl=QUEUE_URL,
            MaxNumberOfMessages=1,
            WaitTimeSeconds=20,  # Long Polling
            VisibilityTimeout=300  # 5ë¶„ ë™ì•ˆ ë‹¤ë¥¸ Workerê°€ ëª» ê°€ì ¸ê°
        )
        
        messages = response.get('Messages', [])
        if not messages:
            continue
            
        for msg in messages:
            body = json.loads(msg['Body'])
            job_id = body['job_id']
            
            try:
                # 2. Docker ì»¨í…Œì´ë„ˆ ì‹¤í–‰
                result = run_container(body)
                
                # 3. Output íŒŒì¼ S3 ì—…ë¡œë“œ
                output_files = upload_outputs(job_id)
                
                # 4. ê²°ê³¼ë¥¼ Redisë¡œ ë°œí–‰
                result_payload = {
                    'job_id': job_id,
                    'status': 'completed',
                    'result': result,
                    'output_files': output_files
                }
                redis_client.publish(f'result:{job_id}', json.dumps(result_payload))
                
            except Exception as e:
                # ì‹¤íŒ¨ ì‹œì—ë„ Redisë¡œ ì—ëŸ¬ ë°œí–‰
                error_payload = {
                    'job_id': job_id,
                    'status': 'failed',
                    'error': str(e)
                }
                redis_client.publish(f'result:{job_id}', json.dumps(error_payload))
            
            finally:
                # 5. SQS ë©”ì‹œì§€ ì‚­ì œ
                sqs.delete_message(
                    QueueUrl=QUEUE_URL,
                    ReceiptHandle=msg['ReceiptHandle']
                )

if __name__ == '__main__':
    print("Worker Agent started...")
    poll_and_execute()
```

#### 3.4 executor.py - Docker ì‹¤í–‰
```python
import docker
import boto3
import os
import tempfile
import zipfile

s3 = boto3.client('s3')
docker_client = docker.from_env()

def run_container(job: dict) -> dict:
    job_id = job['job_id']
    s3_key = job['s3_key']
    runtime = job['runtime']
    handler = job['handler']
    payload = job.get('payload', {})
    timeout = job.get('timeout', 300)
    
    # 1. S3ì—ì„œ ì½”ë“œ ë‹¤ìš´ë¡œë“œ
    with tempfile.TemporaryDirectory() as tmpdir:
        code_path = os.path.join(tmpdir, 'code.zip')
        s3.download_file(os.environ['S3_CODE_BUCKET'], s3_key, code_path)
        
        # ì••ì¶• í•´ì œ
        extract_path = os.path.join(tmpdir, 'code')
        with zipfile.ZipFile(code_path, 'r') as zip_ref:
            zip_ref.extractall(extract_path)
        
        # 2. Output ë””ë ‰í† ë¦¬ ìƒì„±
        output_path = f'/tmp/output/{job_id}'
        os.makedirs(output_path, exist_ok=True)
        
        # 3. Docker ì´ë¯¸ì§€ ì„ íƒ
        image = get_runtime_image(runtime)
        
        # 4. í™˜ê²½ë³€ìˆ˜ ì„¤ì • (AI_ENDPOINT í¬í•¨!)
        environment = {
            'PAYLOAD': json.dumps(payload),
            'HANDLER': handler,
            'AI_ENDPOINT': os.environ['AI_ENDPOINT'],  # ì¤‘ìš”!
            'JOB_ID': job_id
        }
        
        # 5. ë³¼ë¥¨ ë§ˆìš´íŠ¸ ì„¤ì •
        volumes = {
            extract_path: {'bind': '/code', 'mode': 'ro'},
            output_path: {'bind': '/output', 'mode': 'rw'}  # Output Binding
        }
        
        # 6. ì»¨í…Œì´ë„ˆ ì‹¤í–‰
        container = docker_client.containers.run(
            image=image,
            command=f'python /code/{handler.replace(".", "/")}.py',
            environment=environment,
            volumes=volumes,
            detach=True,
            mem_limit='512m',
            cpu_period=100000,
            cpu_quota=50000,  # 0.5 CPU
            network_mode='bridge'  # AI Node ì ‘ê·¼ ê°€ëŠ¥
        )
        
        # 7. ê²°ê³¼ ëŒ€ê¸°
        result = container.wait(timeout=timeout)
        logs = container.logs().decode('utf-8')
        
        # 8. ì»¨í…Œì´ë„ˆ ì •ë¦¬
        container.remove()
        
        return {
            'exit_code': result['StatusCode'],
            'logs': logs
        }

def get_runtime_image(runtime: str) -> str:
    """ëŸ°íƒ€ì„ì— ë§ëŠ” Docker ì´ë¯¸ì§€ ë°˜í™˜"""
    images = {
        'python3.9': 'nanogrid/python:3.9-fat',
        'python3.10': 'nanogrid/python:3.10-fat',
        'python3.11': 'nanogrid/python:3.11-fat',
        'nodejs18.x': 'nanogrid/node:18-fat'
    }
    return images.get(runtime, 'nanogrid/python:3.9-fat')
```

#### 3.5 uploader.py - Output Binding (S3 ì—…ë¡œë“œ)
```python
import boto3
import os
from typing import List

s3 = boto3.client('s3')
BUCKET = os.environ['S3_USER_DATA_BUCKET']

def upload_outputs(job_id: str) -> List[str]:
    """
    /tmp/output/{job_id} í´ë”ì˜ ëª¨ë“  íŒŒì¼ì„ S3ì— ì—…ë¡œë“œí•˜ê³ 
    URL ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    output_path = f'/tmp/output/{job_id}'
    uploaded_urls = []
    
    if not os.path.exists(output_path):
        return uploaded_urls
    
    for filename in os.listdir(output_path):
        filepath = os.path.join(output_path, filename)
        if os.path.isfile(filepath):
            s3_key = f'outputs/{job_id}/{filename}'
            
            # S3 ì—…ë¡œë“œ
            s3.upload_file(filepath, BUCKET, s3_key)
            
            # URL ìƒì„± (Public ë˜ëŠ” Presigned)
            url = f'https://{BUCKET}.s3.ap-northeast-2.amazonaws.com/{s3_key}'
            uploaded_urls.append(url)
    
    # ë¡œì»¬ íŒŒì¼ ì •ë¦¬
    import shutil
    shutil.rmtree(output_path, ignore_errors=True)
    
    return uploaded_urls
```

#### 3.6 Docker ì´ë¯¸ì§€ ë¹Œë“œ (Fat Image)

ì‚¬ìš©ì ì½”ë“œì—ì„œ ìì£¼ ì“°ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ë¯¸ë¦¬ í¬í•¨í•œ ì´ë¯¸ì§€ë¥¼ ë¹Œë“œí•©ë‹ˆë‹¤.

```dockerfile
# Dockerfile.python-fat
FROM python:3.9-slim

# ìì£¼ ì‚¬ìš©ë˜ëŠ” íŒ¨í‚¤ì§€ ì‚¬ì „ ì„¤ì¹˜
RUN pip install --no-cache-dir \
    requests \
    numpy \
    pandas \
    pillow \
    boto3 \
    httpx

# ì‘ì—… ë””ë ‰í† ë¦¬
WORKDIR /code

# Output ë””ë ‰í† ë¦¬
RUN mkdir -p /output
```

```bash
# ë¹Œë“œ ë° í‘¸ì‹œ
docker build -t nanogrid/python:3.9-fat -f Dockerfile.python-fat .
# ECR ë˜ëŠ” Docker Hubì— í‘¸ì‹œ
```

#### 3.7 Worker ë°°í¬ (systemd ì„œë¹„ìŠ¤)
```bash
# /etc/systemd/system/nanogrid-worker.service
[Unit]
Description=NanoGrid Worker Agent
After=network.target docker.service

[Service]
Type=simple
User=ubuntu
WorkingDirectory=/home/ubuntu/nanogrid-worker
ExecStart=/usr/bin/python3 agent.py
Restart=always
RestartSec=10
Environment="PATH=/usr/local/bin:/usr/bin"

[Install]
WantedBy=multi-user.target
```

```bash
sudo systemctl daemon-reload
sudo systemctl enable nanogrid-worker
sudo systemctl start nanogrid-worker
```

---

## ğŸ§  4. AI Node Team

### ğŸ“Œ ëª©í‘œ
EC2 ë¶€íŒ… ì‹œ Ollama LLM ì„œë²„ê°€ ìë™ìœ¼ë¡œ ì¤€ë¹„ë˜ë„ë¡ í•©ë‹ˆë‹¤.  
Workerì—ì„œ `AI_ENDPOINT` í™˜ê²½ë³€ìˆ˜ë¡œ ì ‘ê·¼í•©ë‹ˆë‹¤.

### âœ… ì™„ë£Œëœ ì‘ì—… (Terraform)
- [x] AI Node EC2 ìƒì„± (t3.large, Private-Data Subnet)
- [x] ê³ ì • IP í• ë‹¹: `10.0.20.100`
- [x] Security Group: Worker SGì—ì„œë§Œ 11434 í¬íŠ¸ ì ‘ê·¼ í—ˆìš©
- [x] User Data ìŠ¤í¬ë¦½íŠ¸ (Docker + Ollama ìë™ ì„¤ì¹˜)

### ğŸ”² ì¶”ê°€ ì‘ì—…

#### 4.1 User Data ìŠ¤í¬ë¦½íŠ¸ (í˜„ì¬ Terraformì— í¬í•¨ë¨)
```bash
#!/bin/bash
set -e

# Docker ì„¤ì¹˜
apt-get update
apt-get install -y docker.io
systemctl start docker
systemctl enable docker

# Ollama ì»¨í…Œì´ë„ˆ ì‹¤í–‰
docker run -d \
  --name ollama \
  --restart always \
  -p 11434:11434 \
  -e OLLAMA_HOST=0.0.0.0 \
  ollama/ollama

# ì»¨í…Œì´ë„ˆ ì¤€ë¹„ ëŒ€ê¸°
sleep 30

# ëª¨ë¸ ì‚¬ì „ ë‹¤ìš´ë¡œë“œ (Cold Start ë°©ì§€)
docker exec ollama ollama pull llama3:8b
```

#### 4.2 ìˆ˜ë™ ëª¨ë¸ ê´€ë¦¬ (SSH ì ‘ì† í•„ìš”)
```bash
# AI NodeëŠ” Private Subnetì´ë¯€ë¡œ Bastion ë˜ëŠ” Session Manager í•„ìš”
# Controller EC2ë¥¼ Bastionìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥

# Controllerì—ì„œ AI Nodeë¡œ SSH (ê°™ì€ VPC)
ssh -i key.pem ubuntu@10.0.20.100

# ëª¨ë¸ ëª©ë¡ í™•ì¸
docker exec ollama ollama list

# ì¶”ê°€ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
docker exec ollama ollama pull phi3:mini      # ê°€ë²¼ìš´ ëª¨ë¸
docker exec ollama ollama pull codellama:7b   # ì½”ë“œ íŠ¹í™”
docker exec ollama ollama pull mistral:7b     # ë²”ìš©

# ëª¨ë¸ ì‚­ì œ (ë””ìŠ¤í¬ ê³µê°„ í™•ë³´)
docker exec ollama ollama rm llama3:8b
```

#### 4.3 Ollama API ì‚¬ìš©ë²• (Worker/ì‚¬ìš©ì ì½”ë“œì—ì„œ)
```python
import requests
import os

AI_ENDPOINT = os.environ.get('AI_ENDPOINT', 'http://10.0.20.100:11434')

def generate_text(prompt: str, model: str = 'llama3:8b') -> str:
    """í…ìŠ¤íŠ¸ ìƒì„±"""
    response = requests.post(
        f'{AI_ENDPOINT}/api/generate',
        json={
            'model': model,
            'prompt': prompt,
            'stream': False
        },
        timeout=120
    )
    return response.json()['response']

def chat(messages: list, model: str = 'llama3:8b') -> str:
    """ëŒ€í™”í˜• API"""
    response = requests.post(
        f'{AI_ENDPOINT}/api/chat',
        json={
            'model': model,
            'messages': messages,
            'stream': False
        },
        timeout=120
    )
    return response.json()['message']['content']

# ì‚¬ìš© ì˜ˆì‹œ
result = generate_text("Pythonìœ¼ë¡œ í”¼ë³´ë‚˜ì¹˜ í•¨ìˆ˜ë¥¼ ì‘ì„±í•´ì¤˜")
print(result)
```

#### 4.4 ëª¨ë¸ ê¶Œì¥ ì‚¬ì–‘
| ëª¨ë¸ | í¬ê¸° | ë©”ëª¨ë¦¬ | ìš©ë„ | ì¸ìŠ¤í„´ìŠ¤ |
|------|------|--------|------|----------|
| phi3:mini | 2.3GB | 4GB | ê°€ë²¼ìš´ ì‘ì—… | t3.medium |
| llama3:8b | 4.7GB | 8GB | ë²”ìš© | t3.large |
| codellama:7b | 3.8GB | 8GB | ì½”ë“œ ìƒì„± | t3.large |
| mistral:7b | 4.1GB | 8GB | ë²”ìš© | t3.large |
| llama3:70b | 40GB | 48GB+ | ê³ í’ˆì§ˆ | g4dn.xlarge |

#### 4.5 í—¬ìŠ¤ì²´í¬ ë° ëª¨ë‹ˆí„°ë§
```bash
# Ollama ìƒíƒœ í™•ì¸
curl http://10.0.20.100:11434/api/tags

# ì‘ë‹µ ì˜ˆì‹œ
{
  "models": [
    {"name": "llama3:8b", "size": 4661224676, ...}
  ]
}
```

#### 4.6 ë¹„ìš© ìµœì í™” (ì„ íƒ)
AI Nodeë¥¼ í•­ìƒ ì¼œë‘ë©´ ë¹„ìš©ì´ ë°œìƒí•©ë‹ˆë‹¤. ì‚¬ìš©ëŸ‰ì´ ì ë‹¤ë©´:
- **Spot Instance**: 70% ë¹„ìš© ì ˆê° (ì¤‘ë‹¨ ê°€ëŠ¥ì„± ìˆìŒ)
- **ìŠ¤ì¼€ì¤„ë§**: Lambdaë¡œ ì—…ë¬´ ì‹œê°„ì—ë§Œ Start/Stop
- **ì œê±°**: AI ê¸°ëŠ¥ì´ í•„ìš” ì—†ìœ¼ë©´ Terraformì—ì„œ ì£¼ì„ ì²˜ë¦¬

---

## ğŸ’» 5. Demo / Frontend Team

### ğŸ“Œ ëª©í‘œ
ëª¨ë“  ê¸°ëŠ¥ì´ ì •ìƒ ë™ì‘í•˜ëŠ”ì§€ ê²€ì¦í•  ë°ëª¨ ì‹œë‚˜ë¦¬ì˜¤ì™€ ì½”ë“œë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.

### ğŸ”² ê°œë°œ ì‘ì—…

#### 5.1 í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤

| # | ì‹œë‚˜ë¦¬ì˜¤ | ê²€ì¦ í•­ëª© |
|---|----------|-----------|
| 1 | ê¸°ë³¸ ì‹¤í–‰ | Upload â†’ Run â†’ ê²°ê³¼ ë°˜í™˜ |
| 2 | AI ì—°ë™ | AI_ENDPOINTë¡œ LLM í˜¸ì¶œ |
| 3 | Output Binding | /output í´ë” â†’ S3 ìë™ ì—…ë¡œë“œ |
| 4 | ë¹„ë™ê¸° ëª¨ë“œ | X-Async í—¤ë”ë¡œ 202 ë°˜í™˜ |
| 5 | íƒ€ì„ì•„ì›ƒ | 5ë¶„ ì´ìƒ ì‘ì—… ì²˜ë¦¬ |
| 6 | ì—ëŸ¬ ì²˜ë¦¬ | ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ë©”ì‹œì§€ ë°˜í™˜ |

#### 5.2 ë°ëª¨ 1: Hello World (ê¸°ë³¸ ë™ì‘ í™•ì¸)

**hello.py:**
```python
import json
import os

def handler(event, context):
    payload = json.loads(os.environ.get('PAYLOAD', '{}'))
    name = payload.get('name', 'World')
    return {
        'statusCode': 200,
        'body': f'Hello, {name}!'
    }

if __name__ == '__main__':
    result = handler(None, None)
    print(json.dumps(result))
```

**í…ŒìŠ¤íŠ¸:**
```bash
# 1. ì—…ë¡œë“œ
curl -X POST http://<ALB_DNS>/upload \
  -F "file=@hello.py" \
  -F "function_name=hello" \
  -F "runtime=python3.9" \
  -F "handler=hello.handler"

# ì‘ë‹µ: {"function_id": "abc-123", ...}

# 2. ì‹¤í–‰
curl -X POST http://<ALB_DNS>/run \
  -H "Content-Type: application/json" \
  -d '{"function_id": "abc-123", "payload": {"name": "NanoGrid"}}'

# ì‘ë‹µ: {"status": "completed", "result": {"body": "Hello, NanoGrid!"}}
```

#### 5.3 ë°ëª¨ 2: AI ìš”ì•½ ë´‡ (AI Node ì—°ë™)

**summarizer.py:**
```python
import json
import os
import requests

def handler(event, context):
    payload = json.loads(os.environ.get('PAYLOAD', '{}'))
    text = payload.get('text', '')
    
    if not text:
        return {'error': 'text is required'}
    
    # AI Node í˜¸ì¶œ
    ai_endpoint = os.environ.get('AI_ENDPOINT', 'http://10.0.20.100:11434')
    
    response = requests.post(
        f'{ai_endpoint}/api/generate',
        json={
            'model': 'llama3:8b',
            'prompt': f'ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ 3ì¤„ë¡œ ìš”ì•½í•´ì¤˜:\n\n{text}',
            'stream': False
        },
        timeout=120
    )
    
    summary = response.json()['response']
    
    return {
        'statusCode': 200,
        'original_length': len(text),
        'summary': summary
    }

if __name__ == '__main__':
    result = handler(None, None)
    print(json.dumps(result, ensure_ascii=False))
```

**í…ŒìŠ¤íŠ¸:**
```bash
curl -X POST http://<ALB_DNS>/run \
  -H "Content-Type: application/json" \
  -d '{
    "function_id": "summarizer-id",
    "payload": {
      "text": "ì¸ê³µì§€ëŠ¥(AI)ì€ ì¸ê°„ì˜ í•™ìŠµëŠ¥ë ¥, ì¶”ë¡ ëŠ¥ë ¥, ì§€ê°ëŠ¥ë ¥ì„ ì¸ê³µì ìœ¼ë¡œ êµ¬í˜„í•œ ì»´í“¨í„° ì‹œìŠ¤í…œì…ë‹ˆë‹¤. ë¨¸ì‹ ëŸ¬ë‹, ë”¥ëŸ¬ë‹ ë“±ì˜ ê¸°ìˆ ì„ í†µí•´ ë°œì „í•˜ê³  ìˆìœ¼ë©°, ìì—°ì–´ ì²˜ë¦¬, ì´ë¯¸ì§€ ì¸ì‹, ììœ¨ì£¼í–‰ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ í™œìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤."
    }
  }'
```

#### 5.4 ë°ëª¨ 3: ì´ë¯¸ì§€ ì²˜ë¦¬ (Output Binding)

**image_processor.py:**
```python
import json
import os
from PIL import Image
import io
import base64

def handler(event, context):
    payload = json.loads(os.environ.get('PAYLOAD', '{}'))
    
    # Base64 ì´ë¯¸ì§€ ë””ì½”ë”©
    image_b64 = payload.get('image_base64', '')
    width = payload.get('width', 200)
    height = payload.get('height', 200)
    
    if not image_b64:
        return {'error': 'image_base64 is required'}
    
    # ì´ë¯¸ì§€ ì²˜ë¦¬
    image_data = base64.b64decode(image_b64)
    image = Image.open(io.BytesIO(image_data))
    
    # ë¦¬ì‚¬ì´ì¦ˆ
    resized = image.resize((width, height))
    
    # /output í´ë”ì— ì €ì¥ (Output Binding)
    output_path = '/output/resized.png'
    resized.save(output_path)
    
    return {
        'statusCode': 200,
        'message': 'Image resized and saved to /output',
        'original_size': image.size,
        'new_size': (width, height)
    }

if __name__ == '__main__':
    result = handler(None, None)
    print(json.dumps(result))
```

**í…ŒìŠ¤íŠ¸:**
```bash
# ì´ë¯¸ì§€ë¥¼ Base64ë¡œ ì¸ì½”ë”©
IMAGE_B64=$(base64 -i sample.png)

curl -X POST http://<ALB_DNS>/run \
  -H "Content-Type: application/json" \
  -d "{
    \"function_id\": \"image-processor-id\",
    \"payload\": {
      \"image_base64\": \"$IMAGE_B64\",
      \"width\": 100,
      \"height\": 100
    }
  }"

# ì‘ë‹µì— output_files í•„ë“œ í™•ì¸
# {"output_files": ["https://nanogrid-user-data-xxx.s3.../outputs/job-id/resized.png"]}
```

#### 5.5 ë°ëª¨ 4: ë¹„ë™ê¸° ì‹¤í–‰

```bash
# X-Async í—¤ë” ì¶”ê°€
curl -X POST http://<ALB_DNS>/run \
  -H "Content-Type: application/json" \
  -H "X-Async: true" \
  -d '{"function_id": "long-running-id", "payload": {}}'

# ì¦‰ì‹œ ì‘ë‹µ (202 Accepted)
# {"job_id": "job-xxx", "status": "pending"}

# ë‚˜ì¤‘ì— ìƒíƒœ í™•ì¸
curl http://<ALB_DNS>/status/job-xxx
```

#### 5.6 E2E í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

**test_e2e.sh:**
```bash
#!/bin/bash
set -e

ALB_DNS="nanogrid-alb-xxx.ap-northeast-2.elb.amazonaws.com"
BASE_URL="http://$ALB_DNS"

echo "=== NanoGrid E2E Test ==="

# 1. Health Check
echo "[1/5] Health Check..."
curl -s "$BASE_URL/health" | jq .

# 2. Upload Function
echo "[2/5] Uploading function..."
UPLOAD_RESULT=$(curl -s -X POST "$BASE_URL/upload" \
  -F "file=@hello.py" \
  -F "function_name=test-hello" \
  -F "runtime=python3.9" \
  -F "handler=hello.handler")
echo $UPLOAD_RESULT | jq .
FUNC_ID=$(echo $UPLOAD_RESULT | jq -r '.function_id')

# 3. Run Function (Sync)
echo "[3/5] Running function (sync)..."
curl -s -X POST "$BASE_URL/run" \
  -H "Content-Type: application/json" \
  -d "{\"function_id\": \"$FUNC_ID\", \"payload\": {\"name\": \"Test\"}}" | jq .

# 4. Run Function (Async)
echo "[4/5] Running function (async)..."
ASYNC_RESULT=$(curl -s -X POST "$BASE_URL/run" \
  -H "Content-Type: application/json" \
  -H "X-Async: true" \
  -d "{\"function_id\": \"$FUNC_ID\", \"payload\": {}}")
echo $ASYNC_RESULT | jq .
JOB_ID=$(echo $ASYNC_RESULT | jq -r '.job_id')

# 5. Check Status
echo "[5/5] Checking status..."
sleep 5
curl -s "$BASE_URL/status/$JOB_ID" | jq .

echo "=== Test Complete ==="
```

---

## ğŸ“Š 6. ì „ì²´ ì•„í‚¤í…ì²˜ ìš”ì•½

### ë°ì´í„° íë¦„
```
User Request
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ALB (Multi-AZ) â”‚  â† Public Subnet 1,2
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ HTTP :80
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Controller EC2 â”‚  â† Public Subnet 1 (10.0.1.84)
â”‚  (Express.js)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚         â”‚              â”‚
    â–¼         â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SQS  â”‚ â”‚ Redis â”‚    â”‚ DynamoDB â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚         â”‚
    â”‚         â”‚ Subscribe (ê²°ê³¼ ëŒ€ê¸°)
    â”‚         â”‚
    â–¼         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Worker EC2     â”‚  â† Private-Data Subnet (ASG)
â”‚  (Python Agent) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
    â”‚         â”‚
    â–¼         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  S3   â”‚ â”‚  AI Node  â”‚  â† 10.0.20.100:11434
â”‚(Output)â”‚ â”‚ (Ollama)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### í¬íŠ¸ ë§¤íŠ¸ë¦­ìŠ¤
| From | To | Port | Protocol | ìš©ë„ |
|------|-----|------|----------|------|
| Internet | ALB | 80, 443 | HTTP/S | ì™¸ë¶€ ì ‘ê·¼ |
| ALB | Controller | 80 | HTTP | íŠ¸ë˜í”½ í¬ì›Œë”© |
| Controller | Redis | 6379 | TCP | Pub/Sub |
| Controller | SQS | 443 | HTTPS | ì‘ì—… ë°œí–‰ |
| Worker | SQS | 443 | HTTPS | ì‘ì—… ìˆ˜ì‹  |
| Worker | Redis | 6379 | TCP | ê²°ê³¼ ë°œí–‰ |
| Worker | AI Node | 11434 | HTTP | LLM í˜¸ì¶œ |
| Worker | S3 | 443 | HTTPS | ì½”ë“œ/ê²°ê³¼ |

### í™˜ê²½ë³€ìˆ˜ ì •ë¦¬
| ë³€ìˆ˜ | Controller | Worker | ê°’ |
|------|------------|--------|-----|
| S3_BUCKET | âœ… | - | nanogrid-code-bucket |
| S3_CODE_BUCKET | - | âœ… | nanogrid-code-bucket |
| S3_USER_DATA_BUCKET | - | âœ… | nanogrid-user-data-xxx |
| DYNAMODB_TABLE | âœ… | - | NanoGridFunctions |
| SQS_QUEUE_URL | âœ… | âœ… | https://sqs.../nanogrid-task-queue |
| REDIS_HOST | âœ… | âœ… | nanogrid-redis.xxx.cache.amazonaws.com |
| REDIS_PORT | âœ… | âœ… | 6379 |
| AI_ENDPOINT | - | âœ… | http://10.0.20.100:11434 |

---

## âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸

### Infrastructure (Terraform)
- [x] VPC, Subnet, NAT Gateway
- [x] ALB + Target Group + Listener
- [x] Controller EC2 (Public Subnet)
- [x] Worker ASG (Private Subnet)
- [x] AI Node EC2 (Private Subnet, ê³ ì • IP)
- [x] Security Groups
- [x] IAM Roles & Policies
- [x] S3 Buckets (code, user-data)
- [x] ElastiCache Redis
- [x] CloudWatch Alarms (Auto Scaling)
- [ ] HTTPS (ACM + ALB Listener)
- [ ] Route53 ë„ë©”ì¸

### Backend (Controller)
- [ ] Express ì„œë²„ ê¸°ë³¸ êµ¬ì¡°
- [ ] GET /health
- [ ] POST /upload
- [ ] POST /run (ë™ê¸°)
- [ ] POST /run (ë¹„ë™ê¸°, X-Async)
- [ ] GET /status/:job_id
- [ ] PM2 ë°°í¬

### Data Plane (Worker)
- [ ] agent.py (SQS Polling)
- [ ] executor.py (Docker ì‹¤í–‰)
- [ ] uploader.py (Output Binding)
- [ ] Fat Docker Image ë¹Œë“œ
- [ ] systemd ì„œë¹„ìŠ¤ ë“±ë¡

### AI Node
- [x] EC2 + Docker + Ollama (Terraform user_data)
- [ ] ëª¨ë¸ ë‹¤ìš´ë¡œë“œ í™•ì¸ (llama3:8b)
- [ ] í—¬ìŠ¤ì²´í¬ í™•ì¸

### Demo
- [ ] hello.py (ê¸°ë³¸ ë™ì‘)
- [ ] summarizer.py (AI ì—°ë™)
- [ ] image_processor.py (Output Binding)
- [ ] E2E í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

---

## ğŸ“ ë‹´ë‹¹ì ì—°ë½ì²˜

| íŒŒíŠ¸ | ë‹´ë‹¹ì | ì—­í•  |
|------|--------|------|
| Infrastructure | TBD | Terraform, AWS ë¦¬ì†ŒìŠ¤ |
| Backend | TBD | Controller Express.js |
| Data Plane | TBD | Worker Agent, Docker |
| AI Node | TBD | Ollama, ëª¨ë¸ ê´€ë¦¬ |
| Demo/QA | TBD | í…ŒìŠ¤íŠ¸, ë¬¸ì„œí™” |
